group_by(Country)  %>%
summarise(mean_leftright = mean(leftright, na.rm=TRUE))
#Do the results square with your intuition about politics in the UK?
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum") + theme(legend.position = "none")
ggplot(data, aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum") + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum") + theme(legend.position = "none")
ggplot(data, aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum") + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count))) + geom_bar() + xlab("Vote in 2nd referendum") + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum") + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count), fill = EURef))  + xlab("Vote in 2nd referendum") + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum") + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("abc") + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum") +ylab("#") + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum") + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill = after_stat(x))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill = after_stat(x))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill = after_stat(x))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(data, aes(x = leftright)) +  geom_histogram() + xlab("left-right scale") + geom_vline(aes(xintercept=mean(data$leftright, na.rm = TRUE)))
ggplot(data, aes(x = leftright)) +  geom_histogram() + xlab("left-right scale")
ggplot(data, aes(x = leftright)) +  geom_histogram() + xlab("left-right scale") + geom_vline(aes(xintercept=mean(data$leftright, na.rm = TRUE)))
ggsave("left_right.png") #save histogram
ggsave("left_right.pdf") #save histogram (vectorgraph)
ggplot(data, aes(x=Country, y=leftright)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") #plain plot
ggplot(data, aes(x=Country, y=leftright)) + stat_boxplot(geom = "errorbar",width = 1) +
geom_boxplot()  + ylab("left-right scale") #plain plot
ggplot(data, aes(x=Country, y=leftright)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") #plain plot
ggplot(data, aes(x=Country, y=leftright)) +
geom_boxplot()  + ylab("left-right scale") #plain plot
ggplot(data, aes(x=Country, y=leftright, fill=Country)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") +
theme(legend.position = "none") #Coloured
ggplot(data, aes(x=Country, y=leftright, fill=Country)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") + coord_flip() #flipped
ggplot(data, aes(x=Country, y=leftright, fill=Country)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") #Coloured (with legend)
ggplot(data, aes(x=Country, y=leftright, fill=Country)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") + guides(fill = guide_legend(title = "Legend")) +
scale_fill_hue(labels = c("a", "b", "c")) #customise the legend
ggplot(data, aes(x=Country, y=leftright, fill=Country)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") + guides(fill = guide_legend(title = "asasasas")) +
scale_fill_hue(labels = c("a", "b", "c")) #customise the legend
ggplot(data, aes(x=Country, y=leftright, fill=Country)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") + guides(fill = guide_legend(title = "Legend")) +
scale_fill_hue(labels = c("a", "b", "c")) #customise the legend
data$RAgeE->data$age
data$age[data$age==99]<-NA
data_tab1 <-
data %>%
group_by(age)  %>%
summarise(mean_leave_agg = mean(EURef_num, na.rm=TRUE))
data_tab1
View(data_tab1)
with(data_tab1, cov(age, mean_leave_agg, use="complete.obs"))
with(data_tab1, cov(age, mean_leave_agg))
with(data_tab1, cor(age, mean_leave_agg, use="complete.obs"))
with(data_tab1, cor(age, mean_leave_agg, use="complete.obs")*cor(age, mean_leave_agg, use="complete.obs"))
with(data_tab1, cor(age, mean_leave_agg, use="complete.obs")^2)
a <- lm(mean_leave_agg~age, data=data_tab1)
summary(a)
ggplot(data_tab1 , aes(x=age, y=mean_leave_agg)) +
geom_point(size=2, shape=23) + ylab("Vote leave in 2nd referendum") + xlab("Age")  +  scale_x_continuous(breaks=c(20, 30, 40, 50, 60, 70, 80, 90, 100)) + theme_bw()
ggplot(data_tab1 , aes(x=age, y=mean_leave_agg)) +
geom_point(size=2) + ylab("Vote leave in 2nd referendum") + xlab("Age")  +  scale_x_continuous(breaks=c(20, 30, 40, 50, 60, 70, 80, 90, 100)) + theme_bw()
ggplot(data_tab1 , aes(x=age, y=mean_leave_agg)) +
geom_point(size=2, shape=23) + ylab("Vote leave in 2nd referendum") + xlab("Age")
ggplot(data_tab1 , aes(x=age, y=mean_leave_agg)) +
geom_point(size=2, shape=23) + ylab("Vote leave in 2nd referendum") + xlab("Age")  +  scale_x_continuous(breaks=c(20, 30, 40, 50, 60, 70, 80, 90, 100)) + theme_bw()
ggplot(data_tab1 , aes(x=age, y=mean_leave_agg)) +
geom_point(size=2, shape=23) + geom_smooth(method=lm, se=FALSE) + ylab("Vote leave in 2nd referendum") + xlab("Age") + scale_x_continuous(breaks=c(20, 30, 40, 50, 60, 70, 80, 90, 100)) + theme_bw()
ggplot(data_tab1 , aes(x=age, y=mean_leave_agg)) +
geom_point(size=2, shape=23) + geom_smooth(method=lm, se=TRUE) + ylab("Vote leave in 2nd referendum") + xlab("Age") + scale_x_continuous(breaks=c(20, 30, 40, 50, 60, 70, 80, 90, 100)) + theme_bw()
ggplot(data_tab1 , aes(x=age, y=mean_leave_agg)) +
geom_point(size=2, shape=23) + geom_smooth(method=lm, se=FALSE) + ylab("Vote leave in 2nd referendum") + xlab("Age") + scale_x_continuous(breaks=c(20, 30, 40, 50, 60, 70, 80, 90, 100)) + theme_bw()
url <- 'https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv' #load a cleaned dataset
penguins <- read.csv(url) #read the csv file into a data frame
penguins <- penguins[,-1] #remove first column
View(penguins)
summary(penguins) #simple summary statistics
datasummary_balance(~1,data=penguins) #numeric and categorical variables in one table
datasummary_balance(~1,data=penguins, output="Table1.png") #in a picture (do not recommend)
datasummary_balance(~1,data=penguins, output="Table1.html") #in a webpage
datasummary_balance(~1,data=penguins, output="Table1.docx") #in a webpage
datasummary_balance(~sex,data=penguins) #comparison by sex
datasummary_balance(~1,data=penguins, output="latex") #in latex
datasummary_skim(penguins) #more information for numeric variables only
datasummary_skim(penguins, type = "categorical") #categorical variables only
datasummary(bill_length_mm + body_mass_g ~ sex*(Mean + SD), data=penguins) #customise - select needed variables only
datasummary((`Bill Length (mm)` = bill_length_mm) + (`Body Mass (g)` = body_mass_g)
~ sex*(Mean + (Std.Dev. = SD)), data=penguins) #customise - compare different sexes
datasummary(species+1+island+1~sex*(N+Percent()), data=penguins) #customise - categorical variables +1 for "All"
datasummary_balance(~sex,data=penguins) #comparison by sex
datasummary(bill_length_mm + body_mass_g ~ sex*(Mean + SD), data=penguins) #customise - select needed variables only
rm(list = ls()) # clear workspace
need <- c("modelsummary","tidyverse","rstudioapi","readstata13", "ggplot2") # list packages needed
have <- need %in% rownames(installed.packages()) # checks packages you have
if(any(!have)) install.packages(need[!have]) # install missing packages
invisible(lapply(need, library, character.only=T)) # load needed packages
setwd(dirname(rstudioapi::getSourceEditorContext()$path)) #set working directory to the file directory
list.files()
#read data
data<-read.dta13("bsa2017.dta")
data$EURef<-NA
#Now let's fill in the values of the object
data$EURef[data$EURefb=="Remain a member of the European Union"]<-"Remain"
data$EURef[data$EURefb=="Leave the European Union"]<-"Leave"
data$EURef[data$EURefb=="I would not vote"]<-"Would not vote"
#Let's recode the variable into a numeric binary variable
#First, let's create an empty object
data$EURef_num<-NA #Create an empty object
data$EURef_num[data$EURefb=="Remain a member of the European Union"]<-0
data$EURef_num[data$EURefb=="Leave the European Union"]<-1
data$leftright<-data$leftrigh
data$leftright[data$leftrigh==99]<-NA
#Intro to the tidyverse and the use of "pipes" %>%
#In the tidyverse grammar, pipes are used to perform multiple commands (functions) subsequently, usually starting with a data frame.
#Take the data frame "data" and PIPE it into the count functi
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill = factor(..x..))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill = after_stat(x))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1)) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=factor(EURef))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=factor(..x..))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=after_stat(x)) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=after_stat(x)) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=after_stat(x)) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=after_stat(x)) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=after_stat(x))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=EURef)) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
View(data)
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill = factor(..x..))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=factor(after_stat(x)))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill = factor(..x..))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=factor(after_stat(x)))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
rm(list = ls()) # clear workspace
need <- c("modelsummary","tidyverse","rstudioapi","readstata13", "ggplot2") # list packages needed
have <- need %in% rownames(installed.packages()) # checks packages you have
if(any(!have)) install.packages(need[!have]) # install missing packages
invisible(lapply(need, library, character.only=T)) # load needed packages
setwd(dirname(rstudioapi::getSourceEditorContext()$path)) #set working directory to the file directory
list.files()
#read data
data<-read.dta13("bsa2017.dta")
#Let's make a simple table
with(data, table(Country)) #within the dataframe "data", tabulate the variable "Country"
with(data, table(EURefb)) #within the dataframe "data", tabulate the variable "EURefb"
data$EURef<-NA
data$EURef[data$EURefb=="Remain a member of the European Union"]<-"Remain"
data$EURef[data$EURefb=="Leave the European Union"]<-"Leave"
data$EURef[data$EURefb=="I would not vote"]<-"Would not vote"
data$EURef_num<-NA #Create an empty object
data$EURef_num[data$EURefb=="Remain a member of the European Union"]<-0
data$EURef_num[data$EURefb=="Leave the European Union"]<-1
with(data, table(leftrigh))
data$leftright<-data$leftrigh
data$leftright[data$leftrigh==99]<-NA
data %>%
count(EURef)
data %>%
summarise(mean_leave = mean(EURef_num, na.rm=TRUE))
data %>%
group_by(Country)  %>%
summarise(mean_leave = mean(EURef_num, na.rm=TRUE))
data %>%
group_by(Country)  %>%
summarise(mean_leftright = mean(leftright, na.rm=TRUE))
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(count), fill = EURef)) + geom_bar() + xlab("Vote in 2nd referendum") + theme(legend.position = "none")
ggsave("eu_bar_count.pdf")
ggplot(subset(data, !is.na(EURef)), aes(EURef, after_stat(prop), group=1, fill=factor(after_stat(x)))) + geom_bar() + xlab("Vote in 2nd referendum")  + theme(legend.position = "none")
ggplot(data, aes(x = leftright)) +  geom_histogram() + xlab("left-right scale") + geom_vline(aes(xintercept=mean(data$leftright, na.rm = TRUE)))
ggplot(data, aes(x=Country, y=leftright)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") #plain plot
ggplot(data, aes(x=Country, y=leftright, fill=Country)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") +
theme(legend.position = "none") #Coloured
ggplot(data, aes(x=Country, y=leftright, fill=Country)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") #Coloured (with legend)
ggplot(data, aes(x=Country, y=leftright, fill=Country)) + stat_boxplot(geom = "errorbar",width = 0.25) +
geom_boxplot()  + ylab("left-right scale") + guides(fill = guide_legend(title = "Legend")) +
scale_fill_hue(labels = c("a", "b", "c")) #customise the legend
data$RAgeE->data$age
data$age[data$age==99]<-NA
data_tab1 <-
data %>%
group_by(age)  %>%
summarise(mean_leave_agg = mean(EURef_num, na.rm=TRUE))
data_tab1
#Covariance
with(data_tab1, cov(age, mean_leave_agg, use="complete.obs"))
#R statistic
with(data_tab1, cor(age, mean_leave_agg, use="complete.obs"))
#R squared statistic
with(data_tab1, cor(age, mean_leave_agg, use="complete.obs")*cor(age, mean_leave_agg, use="complete.obs"))
ggplot(data_tab1 , aes(x=age, y=mean_leave_agg)) +
geom_point(size=2, shape=23) + ylab("Vote leave in 2nd referendum") + xlab("Age")  +  scale_x_continuous(breaks=c(20, 30, 40, 50, 60, 70, 80, 90, 100)) + theme_bw()
ggplot(data_tab1 , aes(x=age, y=mean_leave_agg)) +
geom_point(size=2, shape=23) + geom_smooth(method='lm', se=FALSE) + ylab("Vote leave in 2nd referendum") + xlab("Age") + scale_x_continuous(breaks=c(20, 30, 40, 50, 60, 70, 80, 90, 100)) + theme_bw()
url <- 'https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv' #load a cleaned dataset
penguins <- read.csv(url) #read the csv file into a data frame
penguins <- penguins[,-1] #remove first column
summary(penguins) #simple summary statistics
datasummary_balance(~1,data=penguins) #numeric and categorical variables in one table
summary(penguins) #simple summary statistics
datasummary_balance(~1,data=penguins) #numeric and categorical variables in one table
View(penguins)
datasummary(data=penguins)
penguins$year=as.factor(penguins$year)
datasummary_balance(~1,data=penguins) #numeric and categorical variables in one table
datasummary_balance(~1,data=penguins) #numeric and categorical variables in one table
View(penguins)
datasummary_balance(~1,data=penguins) #numeric and categorical variables in one table
penguins <- read_csv(url) #read the csv file into a data frame
summary(penguins) #simple summary statistics
datasummary_balance(~1,data=penguins) #numeric and categorical variables in one table
datasummary_skim(penguins) #more information for numeric variables only
datasummary_skim(penguins, type = "categorical") #categorical variables only
datasummary_balance(~sex,data=penguins) #comparison by sex
rm(list = ls()) # clear workspace
need <- c("modelsummary","rstudioapi","fixest","car") # list packages needed
have <- need %in% rownames(installed.packages()) # checks packages you have
if(any(!have)) install.packages(need[!have]) # install missing packages
invisible(lapply(need, library, character.only=T)) # load needed packages
setwd(dirname(rstudioapi::getSourceEditorContext()$path)) #set working directory to the file directory
list.files()
url <- 'https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv' #load a cleaned dataset
penguins <- read_csv(url) #read the csv file into a data frame
datasummary_balance(~sex,data=penguins, fmt=4, stars=TRUE) #comparison by sex
t1 <- t.test(bill_length_mm~factor(sex), data=penguins)
t1$stderr
t2 <- t.test(bill_depth_mm~factor(sex), data=penguins)
t2$stderr
t3 <- t.test(flipper_length_mm~factor(sex), data=penguins)
t3$stderr
t4 <- t.test(body_mass_g~factor(sex), data=penguins)
t4$stderr
lm1 <- lm(bill_length_mm~factor(sex), data=penguins)
summary(lm1)
lm2 <- lm(bill_depth_mm~factor(sex), data=penguins)
summary(lm2)
lm3 <- lm(flipper_length_mm~factor(sex), data=penguins)
summary(lm3)
lm4 <- lm(body_mass_g~factor(sex), data=penguins)
summary(lm4)
lm <- list('bill_length_mm'=lm1,'bill_depth_mm'=lm2,'flipper_length_mm'=lm3,'body_mass_g'=lm4)
modelsummary(lm,fmt=4,stars=TRUE, coef_rename=c('factor(sex)male'='difference by sex'))
tab1 <- data.frame('outcome'=c(names(lm1$model)[[1]],names(lm2$model)[[1]],names(lm3$model)[[1]],names(lm4$model)[[1]]),
't-test difference'=c(-get_estimates(t1)$estimate,-get_estimates(t2)$estimate,-get_estimates(t3)$estimate,-get_estimates(t4)$estimate),
'ols difference'=c(coef(lm1)[[2]],coef(lm2)[[2]],coef(lm3)[[2]],coef(lm4)[[2]]),
't-test se'=c(t1$stderr,t2$stderr,t3$stderr,t4$stderr),
'ols se'=c(sqrt(diag(vcov(lm1)))[[2]],sqrt(diag(vcov(lm2)))[[2]],sqrt(diag(vcov(lm3)))[[2]],sqrt(diag(vcov(lm4)))[[2]]))
m1 <- list(tidy=data.frame(
term=c('t-test','ols'),
estimate = c(tab1$t.test.difference[1],tab1$ols.difference[1]),
std.error = c(tab1$t.test.se[1],tab1$ols.se[1]),
p.value= c(t1$p.value,summary(lm1)$coefficients[ ,4][2]))
)
class(m1) <- "modelsummary_list"
m2 <- list(tidy=data.frame(
term=c('t-test','ols'),
estimate = c(tab1$t.test.difference[2],tab1$ols.difference[2]),
std.error = c(tab1$t.test.se[2],tab1$ols.se[2]),
p.value= c(t2$p.value,summary(lm2)$coefficients[ ,4][2]))
)
class(m2) <- "modelsummary_list"
m3 <- list(tidy=data.frame(
term=c('t-test','ols'),
estimate = c(tab1$t.test.difference[3],tab1$ols.difference[3]),
std.error = c(tab1$t.test.se[3],tab1$ols.se[3]),
p.value= c(t3$p.value,summary(lm3)$coefficients[ ,4][2]))
)
class(m3) <- "modelsummary_list"
m4 <- list(tidy=data.frame(
term=c('t-test','ols'),
estimate = c(tab1$t.test.difference[4],tab1$ols.difference[4]),
std.error = c(tab1$t.test.se[4],tab1$ols.se[4]),
p.value= c(t4$p.value,summary(lm4)$coefficients[ ,4][2]))
)
class(m4) <- "modelsummary_list"
m <- list('bill_length_mm'=m1,
'bill_depth_mm'=m2,
'flipper_length_mm'=m3,
'body_mass_g'=m4)
modelsummary(m, stars=T)
#test for hetero - Breusch-Pagan test.
homotest1 <- ncvTest(lm1) #acceptable
homotest2 <- ncvTest(lm2) #very homo
homotest3 <- ncvTest(lm3) #dodgy
homotest4 <- ncvTest(lm4) #hetero for sure
#run ols with robust SE
lm1_robust <- feols(bill_length_mm~factor(sex), data=penguins,vcov='HC1')
summary(lm1_robust)
lm2_robust <- feols(bill_depth_mm~factor(sex), data=penguins,vcov='HC1')
summary(lm2_robust)
lm3_robust <- feols(flipper_length_mm~factor(sex), data=penguins,vcov='HC1')
summary(lm3_robust)
lm4_robust <- feols(body_mass_g~factor(sex), data=penguins,vcov='HC1')
summary(lm4_robust)
m1 <- list(tidy=data.frame(
term=c('t-test','ols',"robust"),
estimate = c(tab1$t.test.difference[1],tab1$ols.difference[1],coef(lm1_robust)[[2]]),
std.error = c(tab1$t.test.se[1],tab1$ols.se[1],lm1_robust$se[[2]]),
p.value= c(t1$p.value,summary(lm1)$coefficients[ ,4][2],get_estimates(lm1_robust)$p.value[[2]]))
)
class(m1) <- "modelsummary_list"
m2 <- list(tidy=data.frame(
term=c('t-test','ols',"robust"),
estimate = c(tab1$t.test.difference[2],tab1$ols.difference[2],coef(lm2_robust)[[2]]),
std.error = c(tab1$t.test.se[2],tab1$ols.se[2],lm2_robust$se[[2]]),
p.value= c(t2$p.value,summary(lm2)$coefficients[ ,4][2],get_estimates(lm2_robust)$p.value[[2]]))
)
class(m2) <- "modelsummary_list"
m3 <- list(tidy=data.frame(
term=c('t-test','ols',"robust"),
estimate = c(tab1$t.test.difference[3],tab1$ols.difference[3],coef(lm3_robust)[[2]]),
std.error = c(tab1$t.test.se[3],tab1$ols.se[3],lm3_robust$se[[2]]),
p.value= c(t3$p.value,summary(lm3)$coefficients[ ,4][2],get_estimates(lm3_robust)$p.value[[2]]))
)
class(m3) <- "modelsummary_list"
m4 <- list(tidy=data.frame(
term=c('t-test','ols',"robust"),
estimate = c(tab1$t.test.difference[4],tab1$ols.difference[4],coef(lm4_robust)[[2]]),
std.error = c(tab1$t.test.se[4],tab1$ols.se[4],lm4_robust$se[[2]]),
p.value= c(t4$p.value,summary(lm4)$coefficients[ ,4][2],get_estimates(lm4_robust)$p.value[[2]]))
)
class(m4) <- "modelsummary_list"
m <- list('bill_length_mm'=m1,
'bill_depth_mm'=m2,
'flipper_length_mm'=m3,
'body_mass_g'=m4)
modelsummary(m, stars=T)
#dirname(rstudioapi::getSourceEditorContext()$path) #get file path
knitr::opts_chunk$set(
collapse = TRUE,
comment = "##",
message = FALSE,
warning = FALSE,
out.extra = "",
root.dir = "D:/OneDrive - London School of Economics/Desktop/lse assignments/MY459/summative-midterm"
)
rm(list=ls())
need <- c('tidyverse',"quanteda","quanteda.textmodels","kableExtra","caret","glmnet","glmnetUtils","parallel") # list packages needed
have <- need %in% rownames(installed.packages()) # checks packages you have
if(any(!have)) install.packages(need[!have]) # install missing packages
invisible(lapply(need, library, character.only=T))
setwd("D:/OneDrive - London School of Economics/Desktop/lse assignments/MY459/summative-midterm") #change to your own directory when running chunks in R
data_corpus_moviereviews <- data_corpus_moviereviews
dfm <- tokens(data_corpus_moviereviews, remove_punct = TRUE) |>
tokens_wordstem() |> #stemming so words of the same root are treated as the same word, providing better information for the model
tokens_remove(stopwords("english")) |> #removing stopwords so the model focuses on the most important words
dfm() #make a document-feature matrix
# shuffling to split into training and test set
set.seed(123) # for reproducibility
train<- sample(1:ndoc(dfm), 0.8*ndoc(dfm)) #split the data 80/20 into training and testing sets
test <- which(!1:ndoc(dfm) %in% train) #the rest of the data is the test set
docvars(data_corpus_moviereviews, "sentiment") <- docvars(data_corpus_moviereviews, "sentiment") |> relevel(ref="pos") #relevel the sentiment variable so that the positive class is the reference class
# training Naive Bayes model
nb <- textmodel_nb(dfm[train,], docvars(data_corpus_moviereviews, "sentiment")[train])
# predicting labels for test set
preds <- predict(nb, newdata = dfm[test,])
# actual labels for test set
acts <- docvars(data_corpus_moviereviews, "sentiment")[test]
# computing the confusion matrix
cm <- confusionMatrix(data=preds, reference = acts, positive="pos", mode="prec_recall")
cm$table |>
kbl(caption="Confusion matrix of the Naive Bayes Classifier", escape=F) |>
column_spec(1, bold = TRUE) |> kable_styling(full_width = F)
param <- t(nb$param) |> as.data.frame() |> mutate(posneg=pos/neg) |> arrange(desc(posneg)) #find out which words are most important for the classification from PwGc
#cross-validated regularised regression
#cl <- makeCluster(8) #create a cluster for parallel computing
#en_uni <- cva.glmnet(dfm[train,], docvars(data_corpus_moviereviews, "sentiment")[train], family = "binomial", nfolds = 10, outerParallel = cl) #fit regularised logistic regressions on the training set with cross-validation
#stopCluster(cl) #stop the cluster
#find best cv.glmnet with best alphas
#find_model <- function(mods) {
#  loss <- sapply(mods$modlist,function(mod) mod$cvm[mod$lambda == mod$lambda.min])
#  best <- which.min(loss)
#  best_mod <- mods$modlist[[best]]
#  best_mod[['alpha']] <- mods$alpha[best]
#  return(best_mod)
#}
#en_uni <- find_model(en_uni) #find the best model
#save(en_uni, file="en.RData") #save the model
load("en.RData") #load the model
pred_en_uni <- predict(en_uni, dfm[test,], type="class") |> factor(levels=c("pos","neg")) #predict the test set
cm_en_uni <- confusionMatrix(data=pred_en_uni, reference = acts, positive="pos", mode="prec_recall") #compute the confusion matrix
cm_en_uni$table |>
kbl(caption="Confusion matrix of the Elastic Net Classifier wih unigrams", escape=F) |>
column_spec(1, bold = TRUE) |> kable_styling(full_width = F) #print the confusion matrix
# may encounter path problem, run the line in console if necessary
#download.file('https://github.com/lse-my459/pset_data/raw/master/congress-tweets.csv', 'congress-tweets.csv')
# also download smaller sample of tweets
#download.file('https://github.com/lse-my459/pset_data/raw/master/congress-tweets-sample.csv', 'congress-tweets-sample.csv')
#download.file('https://github.com/lse-my459/pset_data/raw/master/candidate-tweets.csv', 'candidate-tweets.csv')
tweets <- read.csv('candidate-tweets.csv', stringsAsFactors=F) # similar issue may occur, run the line in console to solve the problem
#cong <- read.csv("congress-tweets.csv", stringsAsFactors=F)
# If later chunks of code are taking too long, uncomment the following line of code
# It is a 10% sample of the original data, so can be used for testing your answer
# In the final submission, please use the full data
# My advice would be to first knit a document with 10%, copy the html doc elsewhere as a backup,
# then perform a longer knit with the full data
#cong <- read.csv('congress-tweets-sample.csv', stringsAsFactors=F)
#trump <- paste(tweets$text[tweets$screen_name=="realDonaldTrump"], collapse="")
#clinton <- paste(tweets$text[tweets$screen_name=="HillaryClinton"], collapse="")
#cruz <- paste(tweets$text[tweets$screen_name=="tedcruz"], collapse="")
#sanders <- paste(tweets$text[tweets$screen_name=="BernieSanders"], collapse="")
# corpus - this line (and tokenisation later) might take a while, bear in mind for knitting and submission
# also see comment in cell above
#corp <- corpus(c(cong$text, trump, clinton, cruz, sanders))
#save(corp, file="wordscore.RData")
load("wordscore.RData")
corp
#docnames(corp) <- c(cong$screen_name, "Trump", "Clinton", "Cruz", "Sanders")
# reference scores and virgin scores
#refpoints <- c(cong$idealPoint, NA, NA, NA, NA)
#cdfm <- tokens(corp) |> dfm(remove_punct=TRUE) |> dfm_remove(c(stopwords("english"), "t.co", "https", "rt", "amp", "http", "t.c", "can")) #extremely time consuming
# trimming rare terms
#cdfm <- dfm_trim(cdfm, min_docfreq = 2)
#save(corp, cdfm, refpoints, file="wordscore.RData")
#load("wordscore.RData")
#no cross-validation because we are using wordscores
ws <- textmodel_wordscores(cdfm, refpoints, smooth=.5)
# predicted values
preds <- predict(ws, rescaling="lbg") #use LBG (2003) rescaling
load("ws_sm.Rdata") #load model trained on smaller sample for comparison
preds_sm <- predict(ws_sm, rescaling="lbg", newdata=cdfm)
# let's look at the most discriminant words
sw <- sort(coef(ws))
head(sw, n=20) #most left wing words
tail(sw, n=20) |> rev() #most right wing words
data.frame(preds = c(preds,preds_sm),
refpoints = rep(refpoints,2),
Sample = rep(c("Full","10%"), each = length(preds))) |> drop_na() |>
ggplot(aes(x=preds, y=refpoints, color=Sample)) +
geom_point() + theme_bw() +
geom_abline(intercept = 0, slope = 1, linetype = "dashed")  +
xlab("Wordscores estimates") +
ylab("Ideal points from 100 legislators")
preds_ci <- predict(ws, rescaling="lbg", interval="confidence")[["fit"]] |> as.data.frame() |> slice_tail(n=4) |> mutate(Sample="Full") |>
rownames_to_column(var="name") #generate confidence intervals for the 4 candidates
preds_ci_sm <- predict(ws_sm, newdata=cdfm, rescaling="lbg", interval="confidence")[["fit"]] |> as.data.frame() |> slice_tail(n=4) |> mutate(Sample="10%")|>
rownames_to_column(var="name")
preds_ci <- rbind(preds_ci, preds_ci_sm) #combine the two samples
preds_ci <- preds_ci |> mutate(name=fct_reorder(name,rep(fit[1:4],2) ))
#reorder the candidates to match the order of the large sample estimates
# Set the width for dodging
dodge_width <- 0.5 #generated by ChatGPT
preds_ci$vjust <-  #generated by ChatGPT
ifelse(preds_ci$Sample == "Full", -0.5, 1.5)
ggplot(preds_ci, aes(x=fit, y=name, label=round(fit, 3), color=Sample)) + #generated by ChatGPT
geom_point(position = position_dodge(width = dodge_width)) +  # Add dodge to points
geom_text(size = 3, aes(vjust=vjust), position = position_dodge(width = dodge_width)) +  # Add dodge to text
geom_errorbarh(aes(xmin=lwr, xmax=upr), height=0, position = position_dodge(width = dodge_width)) +  # Add dodge to error bars
theme_bw() +
xlab("Wordscores estimates") +
ylab("Candidate") ### generated by copilot auto-completion
test <- which(!(docnames(corp) %in% docnames(ws_sm$x))) |> sample(20)
train <- which(!1:104 %in% test)
ws_valid <- textmodel_wordscores(cdfm[train,], refpoints[train], smooth=.5)
preds_valid <- predict(ws_valid, rescaling="lbg", newdata=cdfm[test,])
preds_sm_valid <- predict(ws_sm, rescaling="lbg", newdata=cdfm[test,])
MSE_valid <- mean((preds_valid - refpoints[test])^2) |> round(3)
MSE_sm_valid <- mean((preds_sm_valid - refpoints[test])^2) |> round(3)
library(keras)
remotes::install_github("rstudio/tensorflow")
install_tensorflow(envname = "r-tensorflow")
library(tensorflow)
install_tensorflow(envname = "r-tensorflow")
reticulate::install_python(version = '<version>')
install_tensorflow(envname = "r-tensorflow")
py_version
py_version()
reticulate::py_version()
library(reticulate)
configure_environment()
py()
use_python()
py_config()
use_python()
use_python("C:/Users/kv989/AppData/Local/Programs/Python/Python311/python.exe")
install_tensorflow()
library(keras)
install.packages("keras")
library(keras)
install_keras()
keras::install_keras()
use_python("C:/Users/kv989/AppData/Local/Programs/Python/Python311/python.exe")
reticulate::py_config()
library(tensorflow)
model <- keras_model_sequential()
library(keras)
library(tensorflow)
library(keras)
reticulate::py_last_error()
install_tensorflow()
library(keras)
model <- keras_model_sequential()
tensorflow::install_tensorflow()
library(keras)
model <- keras_model_sequential()
library(keras)
model <- keras_model_sequential()
reticulate::py_config()
library(tensorflow)
library(keras)
model <- keras_model_sequential()
reticulate::repl_python()
print("hello world")
from tensorflow.keras.models import load_model
