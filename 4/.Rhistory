tidy.bootevent <- function(x, ...) {
ret <- data.frame(
term      = x$estimates$event.dates,
estimate  = x$estimates$estimates,
conf.low  = x$estimates$lower_ci,
conf.high = x$estimates$upper_ci)
ret
}
get_estimates(lm_ev_sum)
lm_ev_sum$estimates$event.dates
lm_ev_sum$estimates
lm_ev_sum$estimates$upper_ci
tidy.bootevent <- function(x, ...) {
ret <- data.frame(
term      = x$estimates$event_dates,
estimate  = x$estimates$estimates,
conf.low  = x$estimates$lower_ci,
conf.high = x$estimates$upper_ci)
ret
}
get_estimates(lm_ev_sum)
modelsummary(lm_ev_sum)
get_estimates(lm_ev)
tidy.bootevent <- function(x, ...) {
ret <- data.frame(
term      = x$estimates$event_dates,
estimate  = x$estimates$estimates,
conf.low  = x$estimates$lower_ci,
conf.high = x$estimates$upper_ci,
p.value   = x$estimates$p.value)
ret
}
modelsummary(lm_ev_sum)
get_estimates(lm_ev_sum)
get_gof(lm_ev)
glance.bootevent <- function(x, ...) {
ret <- data.frame(
r.squared = x$r.squared,
adj.r.squared= x$adj.r.squared,
nobs  = x$nobs)
ret
}
modelsummary(lm_ev_sum)
get_gof(lm_ev_sum)
glance.bootevent <- function(x, ...) {
ret <- data.frame(
r.squared = x$r.squared,
adj.r.squared= x$adj.r.squared,
nobs  = x$nobs)
ret
}
get_gof(lm_ev_sum)
get_estimates(lm_ev_sum)
lm_ev_sum$nobs
glance.bootevent(lm_ev_sum)
lm_ev_sum$adj.r.squared
modelsummary(lm_ev_sum, statistic = 'conf.int', stars=TRUE)
ggplot(es_results, aes(x = event_dates, y = estimates))+ ggtitle("Event Study Style Plot: Treatment Effect Over Time") +
geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), fill = "grey", alpha = 0.5) + geom_line() +
labs(x="Months since treatment",y="Average Treatment Effect on the Treated (ATT)") + geom_hline(yintercept = 0, linetype = "solid", color = "black") +
geom_vline(xintercept = -1, linetype = "dashed") + geom_point(size = 3) +
theme_minimal() + theme(panel.background = element_rect(fill = "white"))
modelsummary(lm_ev_sum, statistic = 'conf.int', stars=TRUE)
get_gof(lm_ev)
get_gof(lm_ev)$r.squared
get_gof(lm_ev)$adj.r.squared
get_gof(lm_ev)$nobs
glance.bootevent <- function(x, ...) {
ret <- data.frame(
r.squared = x$r.squared,
adj.r.squared= x$adj.r.squared,
n  = x$nobs)
ret
}
get_gof(lm_ev_sum)
glance.bootevent(lm_ev_sum)
attributes(lm_ev_sum)
lm_ev_sum$estimates
lm_ev_sum$r.squared
lm_ev_sum$nobs
lm_ev_sum$r.squared
glance.bootevent <- function(x, ...) {
ret <- data.frame(
#    r.squared = x$r.squared,
adj.r.squared= x$adj.r.squared,
n  = x$nobs)
ret
}
get_gof(lv_ev_sum)
get_gof(lm_ev_sum)
data <- subset(data, select = -c(omega, lambda, weights))
data$omega [data$Country == data$Country [data$treated==1][1]] <- 1
T1 <- length(data$Country[data$treated==1])
data$lambda [data$M.unit %in% data$M.unit[data$treated==1]] <- 1/T1
omega.df <- data.frame(Country = rownames(attributes(tau.hat.log)$setup$Y)[-nrow(attributes(tau.hat.log)$setup$Y)], omega = attributes(tau.hat.log)$weights$omega)
lambda.df <- data.frame(M.unit = colnames(attributes(tau.hat.log)$setup$Y)[1:(length(colnames(attributes(tau.hat.log)$setup$Y))-T1)], lambda = attributes(tau.hat.log)$weights$lambda)
data <- merge(data, omega.df, by = "Country", all = TRUE, no.dups = TRUE)
data$omega <- ifelse(is.na(data$omega.x),data$omega.y,data$omega.x)
data <- subset(data, select = -c(omega.x,omega.y))
data <- merge(data, lambda.df, by = "M.unit", all = TRUE, no.dups = TRUE)
data$lambda <- ifelse(is.na(data$lambda.x),data$lambda.y,data$lambda.x)
data <- subset(data, select = -c(lambda.x, lambda.y))
data$weights <- data$lambda * data$omega
data_only <- subset(data, weights!=0)
lm_sdid <- feols(logbilateral.trade ~ treated + factor(Country) + factor(M.unit), data = data_only, weights = data_only$weights)
dqrng::dqset.seed(seed)
lm_sdid_wild <-  boottest(lm_sdid, param="treated", B=999, clustid="Country", fe=NULL, type="webb")
#make event studies plot
data_es <- subset(data[order(data$Unit,data$M.unit),], weights!=0)
data_es$time_to_treat = ifelse(data_es$Unit==1, data_es$M.unit, 0)
lm_ev <- feols(logbilateral.trade ~ i(time_to_treat, treated, ref=-3) + factor(Country) + factor(M.unit), data = data_es, weights = data_es$weights)
es_results <- data.frame(event_dates = numeric(), estimates = numeric(), lower_ci = numeric(),
upper_ci = numeric(), p.value=numeric(), stringsAsFactors = FALSE)
for (x in 0:8){
dqrng::dqset.seed(seed)
lm_ev_wild <- boottest(lm_ev, param=paste0("time_to_treat::",x,":treated"), B=999, clustid="Country", fe=NULL, type="webb")
es_results[x+1,1] <- x
es_results[x+1,2] <- lm_ev_wild$point_estimate
es_results[x+1,3] <- lm_ev_wild$conf_int[1]
es_results[x+1,4] <- lm_ev_wild$conf_int[2]
es_results[x+1,5] <- lm_ev_wild$p_val
}
lm_ev_sum=list(nobs=lm_ev$nobs, r.squared=get_gof(lm_ev)$r.squared,
adj.r.squared=get_gof(lm_ev)$adj.r.squared,
estimates=es_results)
class(lm_ev_sum) <- "bootevent"
tidy.bootevent <- function(x, ...) {
ret <- data.frame(
term      = x$estimates$event_dates,
estimate  = x$estimates$estimates,
conf.low  = x$estimates$lower_ci,
conf.high = x$estimates$upper_ci,
p.value   = x$estimates$p.value)
ret
}
glance.bootevent <- function(x, ...) {
ret <- data.frame(
r.squared = x$r.squared,
adj.r.squared= x$adj.r.squared,
n  = x$nobs)
ret
}
modelsummary(lm_ev_sum, statistic = 'conf.int', stars=TRUE)
glance.bootevent <- function(x, ...) {
ret <- data.frame(
r.squared = x$r.squared,
adj.r.squared= x$adj.r.squared,
nobs  = x$nobs)
ret
}
modelsummary(lm_ev_sum, statistic = 'conf.int', stars=TRUE)
modelsummary(lm_ev_sum, statistic = 'conf.int', stars=TRUE,gof_map = gofmap)
modelsummary(lm_ev_sum, estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping by country."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(list('Event Study'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping by country."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(list('Event Study'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping by country."),
stars = c('*' = .1, '**' = .05, '***' = .01),
output="output/total_eventstudy(short).html")
glance.bootevent <- function(x, ...) {
ret <- data.frame(
r.squared = x$r.squared,
adj.r.squared= x$adj.r.squared,
nobs  = x$nobs,
fe.u  = 'Yes',
fe.t  = 'Yes')
ret
}
get_gof(lm_ev_sum)
gofmap <- list(list("raw" = "fe.u", "clean" = "FE: Country", "fmt" = NULL),
list("raw" = "fe.t", "clean" = "FE: Time", "fmt" = NULL),
list("raw" = "nobs", "clean" = "Effective N", "fmt" = 0),
list("raw" = "r.squared", "clean" = "R2", "fmt" = 0),
list("raw" = "adj.r.squared", "clean" = "R2 Adj.", "fmt" = 0))
modelsummary(list('Event Study'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping by country."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
lm_did <-  feols(logbilateral.trade ~ treated+ factor(Country) + factor(M.unit), data = data) #did
dqrng::dqset.seed(seed)
lm_did_wild <- boottest(lm_did, param="treated", B=999,clustid="Country", fe=NULL, type="webb")
data <- subset(data, select = -c(omega, lambda, weights)) #SC starts clear all weights data
data$omega [data$Country == data$Country [data$treated==1][1]] <- 1
data$lambda <- 1
omega.df <- data.frame(Country = rownames(attributes(tau.hat.sc)$setup$Y)[-nrow(attributes(tau.hat.sc)$setup$Y)], omega = attributes(tau.hat.sc)$weights$omega)
data <- merge(data, omega.df, by = "Country", all = TRUE, no.dups = TRUE)
data$omega <- ifelse(is.na(data$omega.x),data$omega.y,data$omega.x)
data <- subset(data, select = -c(omega.x,omega.y))
data$weights <- data$lambda * data$omega
data_only <- subset(data, weights!=0)
lm_sc <- feols(logbilateral.trade ~ treated + factor(M.unit), data = data_only, weights = data_only$weights)
dqrng::dqset.seed(seed)
lm_sc_wild <-  boottest(lm_sc, param="treated", B=999,  clustid="Country", fe=NULL, type="webb")
models <- list()
models[['SDID']] <- lm_sdid_wild
models[['DID']] <- lm_did_wild
models[['SC']] <- lm_sc_wild
glance_custom.boottest <- function(x, ...) {
data.frame(
'fe.u'=ifelse(x$call$object!="lm_sc",'Yes','No'),
'fe.t'= "Yes"
)
}
gofmap <- list(list("raw" = "fe.u", "clean" = "FE: Country", "fmt" = NULL),
list("raw" = "fe.t", "clean" = "FE: Time", "fmt" = NULL),
list("raw" = "nobs", "clean" = "Effective N", "fmt" = 0))
modelsummary(models, estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping by country."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).html")
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping by country."),
modelsummary(models, estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).html")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping\\ by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping\h by country with Webb weights."),
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping\n by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping",
" by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping",
"   by country with Webb weights."),
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping",
"\n by country with Webb weights."),
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"Confidence intervals are calculated through Wild Cluster Bootstrapping",
"\space by country with Webb weights."),
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(models, estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).html")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}](p.value)",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(models, estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}](p.value)",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).html")
modelsummary(models, estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]({p.value})",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).html")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}]({p.value})",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}] ({p.value})",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(models, estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}] ({p.value})",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).html")
modelsummary(models, estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}] ({p.value})",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).docx")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}] ({p.value})",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="latex")
modelsummary(models, estimate = "{estimate}{stars}", statistic = "[{conf.low}, {conf.high}] ({p.value})",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="latex")
setwd("D:/OneDrive - London School of Economics/Desktop/wildboot") #set your own working directory
# Set up: required packages
install.packages(c("stargazer", "ggplot2", "ggthemes", "dplyr", "magrittr", "sampling", "extraDistr", "gtools"))
library(stargazer)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(magrittr)
source("wildBoot.r")
#see also file "wildBoot.r": defines function "bootr" for the wild bootstrap using the Rademacher distribution
#included data:
# 1) main data set (eckhouse_metricsmanagement-data.csv)
# 2) election data (supplementalelectiondates.csv) -- for the election timing section you will also need an external dataset, available from de Benedictis-Kessner, Justin. 2017. “Replication Data for: “Off-Cycle and Out of Office: Election Timing and the Incumbency Advantage”.” URL: https://doi.org/10.7910/DVN/SJBWC3
# 3) data set on cities that never adopt compstat (eckhouse_metricsmanagement-nocompstatdata.csv)
# Load main data set
maindata <- read.csv(file = "eckhouse_metricsmanagement-data.csv")
install.packages(c("stargazer", "ggplot2", "ggthemes", "dplyr", "magrittr", "sampling", "extraDistr", "gtools"))
setwd("D:/OneDrive - London School of Economics/Desktop/wildboot") #set your own working directory
# Set up: required packages
install.packages(c("stargazer", "ggplot2", "ggthemes", "dplyr", "magrittr", "sampling", "extraDistr", "gtools"))
library(stargazer)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(magrittr)
source("wildBoot.r")
#see also file "wildBoot.r": defines function "bootr" for the wild bootstrap using the Rademacher distribution
#included data:
# 1) main data set (eckhouse_metricsmanagement-data.csv)
# 2) election data (supplementalelectiondates.csv) -- for the election timing section you will also need an external dataset, available from de Benedictis-Kessner, Justin. 2017. “Replication Data for: “Off-Cycle and Out of Office: Election Timing and the Incumbency Advantage”.” URL: https://doi.org/10.7910/DVN/SJBWC3
# 3) data set on cities that never adopt compstat (eckhouse_metricsmanagement-nocompstatdata.csv)
# Load main data set
maindata <- read.csv(file = "eckhouse_metricsmanagement-data.csv")
install.packages(c("stargazer", "ggplot2", "ggthemes", "dplyr", "magrittr", "sampling", "extraDistr", "gtools"))
install.packages(c("stargazer", "ggplot2", "ggthemes", "dplyr", "magrittr", "sampling", "extraDistr", "gtools"))
part2arrests <- lm(PART2arrests ~  HASCOMPSTAT + POP + as.factor(AGENCY) + as.factor(YEAR) , data = maindata)
part2arrests.boot <- bootr(lm.model = part2arrests, lm.data = maindata, n.b = 1000, wild = T, dist = "rademacher")
part2arrests.boot
part2arrests.boot <- bootr(lm.model = part2arrests, lm.data = maindata, n.b = 1000, wild = T, dist = "rademacher")
part2arrests.pt1control <- lm(PART2arrests ~  HASCOMPSTAT + POP + YEAR.ACT.ALL.FIELDS  + as.factor(AGENCY) + as.factor(YEAR) , data = maindata)
part2arrests.pt1controldemog <- lm(PART2arrests ~  HASCOMPSTAT + POP + YEAR.ACT.ALL.FIELDS  + popblackpct +popwhitepct + as.factor(AGENCY) + as.factor(YEAR), data = maindata)
part2arrestsDropNYC <- lm(PART2arrests ~  HASCOMPSTAT + POP + as.factor(AGENCY) + as.factor(YEAR), data = subset(maindata, AGENCY != "NEW YORK"))
part2arrestsDropNYC.pt1control <- lm(PART2arrests ~  HASCOMPSTAT + POP + YEAR.ACT.ALL.FIELDS  + as.factor(AGENCY) + as.factor(YEAR), data = subset(maindata, AGENCY != "NEW YORK"))
part2arrestsDropNYC.pt1controldemog <- lm(PART2arrests ~  HASCOMPSTAT + POP + YEAR.ACT.ALL.FIELDS  + popblackpct +popwhitepct + as.factor(AGENCY) + as.factor(YEAR), data = subset(maindata, AGENCY != "NEW YORK"))
part2arrests.pt1control.boot <- bootr(lm.model = part2arrests.pt1control, lm.data = maindata, n.b = 1000, wild = T, dist = "rademacher")
part2arrests.boot <- bootr(lm.model = part2arrests, lm.data = maindata, n.b = 1000, wild = T, dist = "rademacher")
part2arrests.boot <- bootr(lm.model = part2arrests, lm.data = maindata, n.b = 1000, wild = T, dist = "rademacher")
part2arrests.boot <- bootr(lm.model = part2arrests, lm.data = maindata, n.b = 1000, wild = T, dist = "rademacher")
part2arrests.boot <- bootr(lm.model = part2arrests, lm.data = maindata, n.b = 1000, wild = T, dist = "rademacher")
part2arrests.boot <- bootr(lm.model = part2arrests, lm.data = maindata, n.b = 1000, wild = T, dist = "rademacher")
part2arrests.boot <- bootr(lm.model = part2arrests, lm.data = maindata, n.b = 1000, wild = T, dist = "rademacher")
modelsummary(models, estimate = "{estimate} ({p.value}){stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).html")
need <- c("Synth", "reshape2","devtools", "synthdid","ggplot2", "fixest","modelsummary","ggiplot",'fwildclusterboot') # list packages needed
have <- need %in% rownames(installed.packages()) # checks packages you have
if(any(!have)) install.packages(need[!have]) # install missing packages
#devtools::install_github("synth-inference/synthdid") #manually install sdid if the codes above fail to do so automatically
invisible(lapply(need, library, character.only=T)) # load needed packages
modelsummary(models, estimate = "{estimate} ({p.value}){stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).html")
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
modelsummary(models, estimate = "{estimate} ({p.value}){stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).html")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate}({p.value}){stars}", statistic = "[{conf.low}, {conf.high}] ({p.value})",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(list('ATT by month'=lm_ev_sum), estimate = "{estimate} ({p.value}){stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SDID are small due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
output="output/total_eventstudy(short).html")
modelsummary(models, estimate = "{estimate} ({p.value}){stars}", statistic = "[{conf.low}, {conf.high}]",
notes=c("* p < 0.1, ** p < 0.05, *** p < 0.01",
"Effective observations for SC and SDID are smaller due to zero time and unit weights.",
"CIs are calculated through Wild Cluster Bootstrapping by country with Webb weights."),
stars = c('*' = .1, '**' = .05, '***' = .01), gof_map = gofmap,
coef_rename = c("1*treated = 0" = "ATT"),
output="output/total(short).html")
setwd("D:/OneDrive - London School of Economics/Desktop/wildboot") #set your own working directory
# Set up: required packages
install.packages(c("stargazer", "ggplot2", "ggthemes", "dplyr", "magrittr", "sampling", "extraDistr", "gtools"))
library(stargazer)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(magrittr)
source("wildBoot.r")
#see also file "wildBoot.r": defines function "bootr" for the wild bootstrap using the Rademacher distribution
#included data:
# 1) main data set (eckhouse_metricsmanagement-data.csv)
# 2) election data (supplementalelectiondates.csv) -- for the election timing section you will also need an external dataset, available from de Benedictis-Kessner, Justin. 2017. “Replication Data for: “Off-Cycle and Out of Office: Election Timing and the Incumbency Advantage”.” URL: https://doi.org/10.7910/DVN/SJBWC3
# 3) data set on cities that never adopt compstat (eckhouse_metricsmanagement-nocompstatdata.csv)
# Load main data set
maindata <- read.csv(file = "eckhouse_metricsmanagement-data.csv")
########################################################################################################################
# Produce tables for main paper
#################################################
# Table 3: number of part 2 arrests
# run all linear models
part2arrests <- lm(PART2arrests ~  HASCOMPSTAT + POP + as.factor(AGENCY) + as.factor(YEAR) , data = maindata)
part2arrests.pt1control <- lm(PART2arrests ~  HASCOMPSTAT + POP + YEAR.ACT.ALL.FIELDS  + as.factor(AGENCY) + as.factor(YEAR) , data = maindata)
part2arrests.pt1controldemog <- lm(PART2arrests ~  HASCOMPSTAT + POP + YEAR.ACT.ALL.FIELDS  + popblackpct +popwhitepct + as.factor(AGENCY) + as.factor(YEAR), data = maindata)
part2arrestsDropNYC <- lm(PART2arrests ~  HASCOMPSTAT + POP + as.factor(AGENCY) + as.factor(YEAR), data = subset(maindata, AGENCY != "NEW YORK"))
part2arrestsDropNYC.pt1control <- lm(PART2arrests ~  HASCOMPSTAT + POP + YEAR.ACT.ALL.FIELDS  + as.factor(AGENCY) + as.factor(YEAR), data = subset(maindata, AGENCY != "NEW YORK"))
part2arrestsDropNYC.pt1controldemog <- lm(PART2arrests ~  HASCOMPSTAT + POP + YEAR.ACT.ALL.FIELDS  + popblackpct +popwhitepct + as.factor(AGENCY) + as.factor(YEAR), data = subset(maindata, AGENCY != "NEW YORK"))
#run bootr for each model to generate bootstrapped standard error estimates for main variable (Compstat)
#warnings are normal, don't be concerned
part2arrests.boot <- bootr(lm.model = part2arrests, lm.data = maindata, n.b = 1000, wild = T, dist = "rademacher")
stargazer(lm_did)
lm_did <- lm(logbilateral.trade ~ treated+ factor(Country) + factor(M.unit), data = data)
stargazer(lmdid)
stargazer(lm_did)
lm_did <- lm(logbilateral.trade~treated,data=data)
lm_did
summary(lm_did)
stargazer(lm_did)
stargazer(lm_did,se=list(0.103,0.625))
stargazer(lm_did,se=list(0.625,0.103))
rm(list = ls()) # clear workspace
need <- c("modelsummary","rstudioapi","readstata13","fixest","car","parameters") # list packages needed
have <- need %in% rownames(installed.packages()) # checks packages you have
if(any(!have)) install.packages(need[!have]) # install missing packages
invisible(lapply(need, library, character.only=T)) # load needed packages
setwd(dirname(rstudioapi::getSourceEditorContext()$path)) #set working directory to the file directory
list.files()
#read data
data<-read.dta13("caschool.dta")
lm <- feols(testscr~str+PctEL, data=data, vcov="HC1")
modelsummary(lm, stars=T)
fitstat(lm,"f")
lm1 <- feols(testscr~str+expn_stu+PctEL, data=data, vcov="HC1")
models <- list(lm,lm1)
modelsummary(models, stars=T)
options("modelsummary_factory_default" = "kableExtra")
options("modelsummary_factory_default" = "kableExtra")
lm1$df.residual=degrees_of_freedom(lm1) #add degrees of freedom information to the model
))))
)))))
options("modelsummary_factory_default" = "kableExtra")
lm1$df.residual=degrees_of_freedom(lm1) #add degrees of freedom information to the model
rm(list = ls()) # clear workspace
